---
GeekDocCollapseSection: true
weight: 2
---
# How the back end works _v 2.0
### It begins in the front end...    

When a student submission is generated, two files are uploaded as objects  to the submitter S3 bucket.   One is a single `.py` file provided by the student(s), and the other a `.json` file generated by the front end logic containing all the requisite data  to properly process the submission.   
This json file will contain the following:

* submissionid  : a 128 bit MD5 Hash unique to the specific students, admin, event,  and problem.
* admin         : The admin's unique identifier (e.g "m.soltys").  
* event         : A string identifier that is unique to the admin.
* problem       : A string identifier unique to the event.
* tokens        : A(n) list/array of tokens generated by the front end upon event registration.  

This example would be named  `<subid>.json` , where the `subid` is calculated at the front at submission  but can be found here as [./submission_example.json](../json/submission_example.json)



```
{
  "subid": "fc55c0190dde2bc413d8d1e79fb8cca2",
  "admin": "m.soltys",
  "event": "aws_labs",
  "assignment": "lab5_containers",
  "tokens": [
    "d823640ab3b0f7a4a2bc9fc89661e940",
    "240669d4326dea48bba75e066b90b76f",
    "4b31d568d86a9350d746c7c2fe9bf5c8"
  ]
}        
```
S3 buckets only store objects, not files, but a pseudo file system can be achieved by using full paths as keys according to a pseudo file system hierarchy. Using values from the above example, this file and the student submission would be uploaded as:  

```
/m.soltys/aws_labs/lab5_containers/fc55c0190dde2bc413d8d1e79fb8cca2/fc55c0190dde2bc413d8d1e79fb8cca2.py
```

  and   

```
/m.soltys/aws_labs/lab5_containers/fc55c0190dde2bc413d8d1e79fb8cca2/fc55c0190dde2bc413d8d1e79fb8cca2.json
```

Furthermore, at the time of event/assignment creation by an admin, data relevant to the assignment such as the test and grade case input/output files. By the time the example submission from above is submitted, test and grade case files exist in the bucket as:  

```
/m.soltys/aws_labs/lab5_containers/grading/test.in
```

```
/m.soltys/aws_labs/lab5_containers/grading/test.out
```

```
/m.soltys/aws_labs/lab5_containers/grading/grade.in
```

```
/m.soltys/aws_labs/lab5_containers/grading/grade.out
```

These files are provided by the admin, and are formatted such that each line is an input, and for each input the student submission is executed with the input passed in as a command line argument. Ten test case inputs would result in both `.in` and `.out` files that are ten lines in size. `.out` files are the expected output when the respective line of input is passed to the student submission.  

## A new object/file in the S3 bucket triggers a lambda function...

A new object in the submitter S3 bucket triggers a lambda function written in python. This lambda function analyses the name of the new object, and if it is a student submission json file, a message is generated and sent to the submitter SQS queue. This message is a json file with several key value pairs. One of these is the message `body`. An example of the [message body](../json/message_body.json) in a message generated for the creation of the json file from the above example is:  

```
{
  "subdata" : "/m.soltys/aws_labs/lab5_containers/fc55c0190dde2bc413d8d1e79fb8cca2/fc55c0190dde2bc413d8d1e79fb8cca2.json"
}        
```
Once this message arrives to the queue

## The back end makes its inglorious entrance...  

The back end's [processStudentsTestCases.py](./processStudentTestCases.py) will first retrieve the next message from the SQS queue. This master thread polls the queue for a message until a message is found then spawns a worker thread and passes the message in to its constructor. Then the master thread calls  `start()`  on this worker thread, which in turn calls the class method `run()` defined in the ClientThread class. After calling `start()` the master thread continues to poll the queue.      

### Worker Thread  

When the worker thread constructor executes, it populates all instance variables except the student email list. This is done later. The entry point for this thread is the run function.

* extracting the name of the json file from the SQS message.  
* creating a directory using the subid from the subdata filename, for example  
  * `/home/ec2-user/fc55c0190dde2bc413d8d1e79fb8cca2/`   
* changing present working directories into the newly cerated directory, from there retrieving both the newly submitted 
  json and python files from the S3 bucket, for example:  
  * `/home/ec2-user/fc55c0190dde2bc413d8d1e79fb8cca2/fc55c0190dde2bc413d8d1e79fb8cca2.json`  
  * `/home/ec2-user/fc55c0190dde2bc413d8d1e79fb8cca2/fc55c0190dde2bc413d8d1e79fb8cca2.py`
    
### Query database for test case parameters
From the data in the json file, our script will then   
* query the database for the test inputs and outputs, and generate files for comparison, for example `test.in` and `test.out`.   

These files will be formatted so that individual test case input for the specific problem is placed on a new line in `test.in`, 
and the appropriate output expected for each input is placed on a new line in `test.out`.   
The directory structure at this point:  
* `/home/ec2-user/fc55c0190dde2bc413d8d1e79fb8cca2/fc55c0190dde2bc413d8d1e79fb8cca2.json`  
* `/home/ec2-user/fc55c0190dde2bc413d8d1e79fb8cca2/fc55c0190dde2bc413d8d1e79fb8cca2.py`  
* `/home/ec2-user/fc55c0190dde2bc413d8d1e79fb8cca2/test.in`  
* `/home/ec2-user/fc55c0190dde2bc413d8d1e79fb8cca2/test.out`  

### Execute submitted code in Python 3.9 container  
At this point we have the code to execute, the inputs to run, and the appropriate outputs for comparison. We are using a
python 3 docker image with a custom, executable script [executeSubmission.py](./executeSubmission.py) installed that will execute the submitted 
code against all provided inputs from test.in, generating and generating the output file. Our script will now:
* Create a new thread that will in turn execute the appropriate `docker run` command.  
  * `docker run -it --rm --name="subidfc55c0190dde2bc413d8d1e79fb8cca2" -v "$PWD":/usr/src/submitter -w /usr/src/submitter 
    python:3.9 executeSubmission.py fc55c0190dde2bc413d8d1e79fb8cca2`  
    

This will spin up our container and keep it alive until it finishes executing. The present working directory gets bind-mounted
to a newly created directory in the container `/usr/src/submitter`. Read more on the container and how it works [here](./docker/Docker.md).
Since the default for bind mount is read-write, this allows our script in the container to generate an output that can be read 
by our main thread. It is important that our script's  
* Main thread __MUST__ wait for the worker thread to finish executing before moving on.  


### Return output to the front-end via submitter S3 bucket and clean house  

_At the time of this writing it is understood that the way to return the output generated by the user's submission is for the backend to
upload the newly generated `fc55c0190dde2bc413d8d1e79fb8cca2.out` to the submitter S3 bucket for the front end to retrieve._   

Now that our worker thread has finished executing, our script's current directory should contain:  
* `/home/ec2-user/fc55c0190dde2bc413d8d1e79fb8cca2/fc55c0190dde2bc413d8d1e79fb8cca2.json`
* `/home/ec2-user/fc55c0190dde2bc413d8d1e79fb8cca2/fc55c0190dde2bc413d8d1e79fb8cca2.py`
* `/home/ec2-user/fc55c0190dde2bc413d8d1e79fb8cca2/test.in`
* `/home/ec2-user/fc55c0190dde2bc413d8d1e79fb8cca2/test.out`
* `/home/ec2-user/fc55c0190dde2bc413d8d1e79fb8cca2/fc55c0190dde2bc413d8d1e79fb8cca2.out`

Our script will now:  
* upload `fc55c0190dde2bc413d8d1e79fb8cca2.out` to submitter S3 bucket.  
* change working directories up one to `/home/ec2-user/`.  
* delete the directory `/home/ec2-user/fc55c0190dde2bc413d8d1e79fb8cca2/`

Finally, now that the submission has been processed, the working space has been cleaned, and the output generated has been
sent to the next destination, our script must:
* delete the message that was originally retrieved from the submitter SQS queue.  

It is important to remember that when our script initially retrieved the message from the SQS queue, that it doers not _remove_ the 
message from the queue, it only hides it from any other process being able to retrieve it for the ammount of time defined in 
the parameters for the SQS instance.  
